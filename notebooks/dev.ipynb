{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-16T21:31:56.034642Z",
     "start_time": "2024-04-16T21:31:56.003163Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from diff import datasets\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# from diff.positional_embeddings import PositionalEmbedding\n",
    "from diff.models import MLP\n",
    "from diff.noise_scheduler import NoiseScheduler\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    experiment_name: str = 'base'\n",
    "    dataset: str = 'dino'\n",
    "    train_batch_size: int = 32\n",
    "    eval_batch_size: int = 1000\n",
    "    num_epochs: int = 200\n",
    "    learning_rate: float = 1e-3\n",
    "    num_timesteps: int = 50\n",
    "    beta_schedule: str = \"linear\"\n",
    "    embedding_size: int = 128\n",
    "    hidden_size: int = 128\n",
    "    hidden_layers: int = 3\n",
    "    time_embedding: str = \"sinusoidal\"\n",
    "    input_embedding: str = \"sinusoidal\"\n",
    "    save_images_step: int = 1\n",
    "\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 12\u001B[0m\n\u001B[1;32m      2\u001B[0m dataset \u001B[38;5;241m=\u001B[39m datasets\u001B[38;5;241m.\u001B[39mget_dataset(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmoons\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      4\u001B[0m dataloader \u001B[38;5;241m=\u001B[39m DataLoader(\n\u001B[1;32m      5\u001B[0m     dataset, batch_size\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mtrain_batch_size, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, drop_last\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m      7\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mMLP\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhidden_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhidden_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhidden_layers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhidden_layers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[43memb_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtime_emb\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtime_embedding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m---> 12\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_emb\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minput_embedding\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m noise_scheduler \u001B[38;5;241m=\u001B[39m NoiseScheduler(\n\u001B[1;32m     15\u001B[0m     num_timesteps\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mnum_timesteps,\n\u001B[1;32m     16\u001B[0m     beta_schedule\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mbeta_schedule)\n\u001B[1;32m     18\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdamW(\n\u001B[1;32m     19\u001B[0m     model\u001B[38;5;241m.\u001B[39mparameters(),\n\u001B[1;32m     20\u001B[0m     lr\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mlearning_rate,\n\u001B[1;32m     21\u001B[0m )\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/diffusion-DecjxhY6-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1152\u001B[0m, in \u001B[0;36mModule.to\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1148\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1149\u001B[0m                     non_blocking, memory_format\u001B[38;5;241m=\u001B[39mconvert_to_format)\n\u001B[1;32m   1150\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, non_blocking)\n\u001B[0;32m-> 1152\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/diffusion-DecjxhY6-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:802\u001B[0m, in \u001B[0;36mModule._apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    800\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[1;32m    801\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[0;32m--> 802\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    804\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[1;32m    805\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[1;32m    806\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[1;32m    807\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    812\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[1;32m    813\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/diffusion-DecjxhY6-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:802\u001B[0m, in \u001B[0;36mModule._apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    800\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[1;32m    801\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[0;32m--> 802\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    804\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[1;32m    805\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[1;32m    806\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[1;32m    807\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    812\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[1;32m    813\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/diffusion-DecjxhY6-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:825\u001B[0m, in \u001B[0;36mModule._apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    821\u001B[0m \u001B[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001B[39;00m\n\u001B[1;32m    822\u001B[0m \u001B[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001B[39;00m\n\u001B[1;32m    823\u001B[0m \u001B[38;5;66;03m# `with torch.no_grad():`\u001B[39;00m\n\u001B[1;32m    824\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m--> 825\u001B[0m     param_applied \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparam\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    826\u001B[0m should_use_set_data \u001B[38;5;241m=\u001B[39m compute_should_use_set_data(param, param_applied)\n\u001B[1;32m    827\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m should_use_set_data:\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/diffusion-DecjxhY6-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1150\u001B[0m, in \u001B[0;36mModule.to.<locals>.convert\u001B[0;34m(t)\u001B[0m\n\u001B[1;32m   1147\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m convert_to_format \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m t\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m5\u001B[39m):\n\u001B[1;32m   1148\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1149\u001B[0m                 non_blocking, memory_format\u001B[38;5;241m=\u001B[39mconvert_to_format)\n\u001B[0;32m-> 1150\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_floating_point\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_complex\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnon_blocking\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/diffusion-DecjxhY6-py3.11/lib/python3.11/site-packages/torch/cuda/__init__.py:293\u001B[0m, in \u001B[0;36m_lazy_init\u001B[0;34m()\u001B[0m\n\u001B[1;32m    288\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    289\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    290\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultiprocessing, you must use the \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mspawn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m start method\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    291\u001B[0m     )\n\u001B[1;32m    292\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(torch\u001B[38;5;241m.\u001B[39m_C, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_cuda_getDeviceCount\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 293\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTorch not compiled with CUDA enabled\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    294\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _cudart \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    295\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[1;32m    296\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    297\u001B[0m     )\n",
      "\u001B[0;31mAssertionError\u001B[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "dataset = datasets.get_dataset('moons')\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset, batch_size=config.train_batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "model = MLP(\n",
    "    hidden_size=config.hidden_size,\n",
    "    hidden_layers=config.hidden_layers,\n",
    "    emb_size=config.embedding_size,\n",
    "    time_emb=config.time_embedding,\n",
    "    input_emb=config.input_embedding).to(device)\n",
    "\n",
    "noise_scheduler = NoiseScheduler(\n",
    "    num_timesteps=config.num_timesteps,\n",
    "    beta_schedule=config.beta_schedule)\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=config.learning_rate,\n",
    ")\n",
    "\n",
    "global_step = 0\n",
    "frames = []\n",
    "losses = []\n",
    "\n",
    "print(\"Training model...\")\n",
    "\n",
    "for epoch in range(config.num_epochs):\n",
    "    model.train()\n",
    "    for step, batch in enumerate(dataloader):\n",
    "        batch = batch[0]\n",
    "        noise = torch.randn(batch.shape)\n",
    "        timesteps = torch.randint(\n",
    "            0, noise_scheduler.num_timesteps, (batch.shape[0],)\n",
    "        ).long()\n",
    "        noisy = noise_scheduler.add_noise(batch, noise, timesteps)\n",
    "        noise_pred = model(noisy.to(device), timesteps.to(device))\n",
    "        loss = F.mse_loss(noise_pred, noise.to(device))\n",
    "        loss.backward(loss)\n",
    "\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # progress_bar.update(1)\n",
    "        # logs = {\"loss\": loss.detach().item(), \"step\": global_step}\n",
    "        losses.append(loss.detach().item())\n",
    "\n",
    "        # progress_bar.set_postfix(**logs)\n",
    "        if global_step % 300 == 0:\n",
    "            print(f'{epoch}|{global_step} loss={loss.detach().item():.2f}')\n",
    "\n",
    "        global_step += 1\n",
    "\n",
    "    if epoch % config.save_images_step == 0 or epoch == config.num_epochs - 1:\n",
    "        # generate data with the model to later visualize the learning process\n",
    "        model.eval()\n",
    "        sample = torch.randn(config.eval_batch_size, 2)\n",
    "        timesteps = list(range(len(noise_scheduler)))[::-1]\n",
    "        for i, t in enumerate(timesteps):\n",
    "            t = torch.from_numpy(np.repeat(t, config.eval_batch_size)).long()\n",
    "            with torch.no_grad():\n",
    "                residual = model(sample.to(device), t.to(device)).to('cpu')\n",
    "            sample = noise_scheduler.step(residual, t[0], sample)\n",
    "        frames.append(sample.numpy())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T21:31:59.422734Z",
     "start_time": "2024-04-16T21:31:59.292540Z"
    }
   },
   "id": "e830f5fed50c9b10",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(\"Saving model...\")\n",
    "outdir = f\"exps/{config.experiment_name}\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "torch.save(model.state_dict(), f\"{outdir}/model.pth\")\n",
    "\n",
    "print(\"Saving images...\")\n",
    "imgdir = f\"{outdir}/images\"\n",
    "os.makedirs(imgdir, exist_ok=True)\n",
    "frames = np.stack(frames)\n",
    "xmin, xmax = -6, 6\n",
    "ymin, ymax = -6, 6\n",
    "for i, frame in enumerate(frames):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.scatter(frame[:, 0], frame[:, 1])\n",
    "    plt.xlim(xmin, xmax)\n",
    "    plt.ylim(ymin, ymax)\n",
    "    plt.savefig(f\"{imgdir}/{i:04}.png\")\n",
    "    plt.close()\n",
    "\n",
    "print(\"Saving loss as numpy array...\")\n",
    "np.save(f\"{outdir}/loss.npy\", np.array(losses))\n",
    "\n",
    "print(\"Saving frames...\")\n",
    "np.save(f\"{outdir}/frames.npy\", frames)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc6e46818d5cd71d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
